{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQjHxWl9gvCL"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "\n",
        "k = 3\n",
        "\n",
        "class cluster_node:\n",
        "\tdef __init__(self, vec, id, left=None, right=None, distance=0.0, node_vector = None): #firstly initializing all nodes \n",
        "\t\tself.leftnode = left\n",
        "\t\tself.rightnode = right\n",
        "\t\tself.vec = vec\n",
        "\t\tself.id = id\n",
        "\t\tself.distance = distance\n",
        "\t\tif node_vector is None:\n",
        "\t\t\tself.node_vector = [self.id]\n",
        "\t\telse:\n",
        "\t\t\tself.node_vector = node_vector[:]\n",
        "\n",
        "def euc_distance(vec1, vec2):\n",
        "\treturn np.sqrt(sum((vec1 - vec2) ** 2))\n",
        "\n",
        "def min_dist(clust1, clust2, distances):\n",
        "\td = 12123123123123\n",
        "\tfor i in clust1.node_vector:\n",
        "\t\tfor j in clust2.node_vector:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tdistance = distances[(i,j)]\n",
        "\t\t\texcept:\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tdistance = distances[(j,i)]\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tdistance = euc_distance(clust1.vec, clust2.vec)\n",
        "\t\t\tif distance < d:\n",
        "\t\t\t\td = distance\n",
        "\treturn d\n",
        "\n",
        "def agglomerative_clustering(data, distance):\n",
        "\t# cluster the rows of the data matrix\n",
        "\tdistances = {}\n",
        "\tcurrentclustid = -1\n",
        "\n",
        "\t# cluster nodes are initially just the individual rows\n",
        "\tnodes = [cluster_node(np.array(data[i]), id=i) for i in range(len(data))]\n",
        "\n",
        "\twhile len(nodes) > k:\n",
        "\t\tlowestpair = (0,1)\n",
        "\t\tclosest = euc_distance(nodes[0].vec,nodes[1].vec)\n",
        "\t\n",
        "\t\t# loop through every pair looking for the smallest distance\n",
        "\t\tfor i in range(len(nodes)):\n",
        "\t\t\tfor j in range(i+1,len(nodes)):\n",
        "\t\t\t\t# distances is the cache of distance calculations\n",
        "\t\t\t\tif (nodes[i].id,nodes[j].id) not in distances:\n",
        "\t\t\t\t\tif distance == \"min\":\n",
        "\t\t\t\t\t\tdistances[(nodes[i].id,nodes[j].id)] = min_dist(nodes[i], nodes[j], distances)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tdistances[(nodes[i].id,nodes[j].id)] = euc_distance(nodes[i].vec,nodes[j].vec)\n",
        "\t\t\n",
        "\t\t\t\td = distances[(nodes[i].id,nodes[j].id)]\n",
        "\t\t\n",
        "\t\t\t\tif d < closest:\n",
        "\t\t\t\t\tclosest = d\n",
        "\t\t\t\t\tlowestpair = (i,j)\n",
        "\t\t\n",
        "\t\t# calculate the average of the two nodes\n",
        "\t\tlen0 = len(nodes[lowestpair[0]].node_vector)\n",
        "\t\tlen1 = len(nodes[lowestpair[1]].node_vector)\n",
        "\t\tmean_vector = [(len0*nodes[lowestpair[0]].vec[i] + len1*nodes[lowestpair[1]].vec[i])/(len0 + len1) \\\n",
        "\t\t\t\t\t\tfor i in range(len(nodes[0].vec))]\n",
        "\t\t\n",
        "\t\t# create the new cluster node\n",
        "\t\tnew_node = cluster_node(np.array(mean_vector), currentclustid, left = nodes[lowestpair[0]], right = nodes[lowestpair[1]], \\\n",
        "\t\t\tdistance = closest, node_vector = nodes[lowestpair[0]].node_vector + nodes[lowestpair[1]].node_vector)\n",
        "\t\t\n",
        "\t\t# cluster ids that weren't in the original set are negative\n",
        "\t\tcurrentclustid -= 1\n",
        "\t\tdel nodes[lowestpair[1]]\n",
        "\t\tdel nodes[lowestpair[0]]\n",
        "\t\tnodes.append(new_node)\n",
        "\n",
        "\treturn nodes\n",
        "\n",
        "def main():\n",
        "\t# Generate data\n",
        "\t# df = pd.read_csv('./segmentation.data.modified')\n",
        "\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  import io\n",
        "  df = pd.read_csv(io.BytesIO(uploaded['Filename.csv']))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tcenters = [[1, 1], [-1, -1], [1, -1]]\n",
        "\tX, _ = make_blobs(n_samples = 90, centers = centers, cluster_std = 0.5)\n",
        "\tdf = pd.DataFrame(X) ## convert to DF\n",
        "\n",
        "\t# Visualize the data\n",
        "\tf = plt.figure(1)\n",
        "\tplt.scatter(df[0],df[1])\n",
        "\tf.show()\n",
        "\tcolorset = ['red', 'green', 'blue', 'yellow', 'brown', 'orange', 'black']\n",
        "\n",
        "\tdata = np.array(df)\n",
        "\n",
        "\n",
        "\t# Min criterion agglomerative clustering\n",
        "\tg = plt.figure(3)\n",
        "\tcluster = agglomerative_clustering(data, \"min\")\n",
        "\t# plt.scatter(cluster.leftnode.vec[0], cluster.leftnode.vec[1], color = 'yellow')\n",
        "\t# plt.scatter(cluster.rightnode.leftnode.vec[0], cluster.rightnode.leftnode.vec[1], color = 'red')\n",
        "\t# plt.scatter(cluster.rightnode.rightnode.vec[0], cluster.rightnode.rightnode.vec[1], color = 'green')\n",
        "\tj = 0\n",
        "\tfor i in cluster:\n",
        "\t\tplt.scatter(data[i.node_vector].T[0], data[i.node_vector].T[1], color = colorset[j])\n",
        "\t\tj += 1\n",
        "\tg.show()\n",
        "\traw_input()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tmain()"
      ]
    }
  ]
}